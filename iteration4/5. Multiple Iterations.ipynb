{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "894ccfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/INFOSYS722/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/23 22:21:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "# findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "findspark.init('../spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('multiple_iterations').getOrCreate()\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier, DecisionTreeClassifier,\\\n",
    "                                       LogisticRegression, MultilayerPerceptronClassifier)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import ChiSqSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d4be7",
   "metadata": {},
   "source": [
    "#### Read the previouly cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e0f14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('cleaned.csv', header=True)\n",
    "# turn type string into double\n",
    "cols = ['HighBP', 'HighChol', 'CholCheck',\n",
    "       'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits',\n",
    "       'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost',\n",
    "       'DiffWalk', 'Sex', 'BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age',\n",
    "       'Education', 'Income']\n",
    "df = df.withColumn('Diabetes',col('Diabetes').cast('double'))\n",
    "for c in cols:\n",
    "    df = df.withColumn(c,col(c).cast('double'))\n",
    "    \n",
    "assembler = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "major_df = df.filter(col(\"Diabetes\") == 0)\n",
    "minor_df = df.filter(col(\"Diabetes\") == 1)\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "sampled_majority_df = major_df.sample(False, 1/ratio)\n",
    "balanced_data = sampled_majority_df.unionAll(minor_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011ddc3",
   "metadata": {},
   "source": [
    "#### Instead of keeping 15 features, we can iterate with more or less number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098bbc98",
   "metadata": {},
   "source": [
    "13 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2441981f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Diabetes',\n",
       " 'HighBP',\n",
       " 'HighChol',\n",
       " 'CholCheck',\n",
       " 'Smoker',\n",
       " 'Stroke',\n",
       " 'HeartDiseaseorAttack',\n",
       " 'PhysActivity',\n",
       " 'Fruits',\n",
       " 'Veggies',\n",
       " 'AnyHealthcare',\n",
       " 'NoDocbcCost',\n",
       " 'DiffWalk']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_13 = ChiSqSelector(featuresCol=\"features\", outputCol=\"selected_features\", \\\n",
    "                         labelCol=\"Diabetes\", numTopFeatures=13)\n",
    "model_13 = selector_13.fit(balanced_data)\n",
    "df_13 = model_13.transform(balanced_data)\n",
    "selected_indices_13 = model_13.selectedFeatures\n",
    "selected_feature_names_13 = [df_13.columns[index] for index in selected_indices_13]\n",
    "selected_feature_names_13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aea1d1",
   "metadata": {},
   "source": [
    "18 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb029298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Diabetes',\n",
       " 'HighBP',\n",
       " 'HighChol',\n",
       " 'CholCheck',\n",
       " 'Smoker',\n",
       " 'Stroke',\n",
       " 'HeartDiseaseorAttack',\n",
       " 'PhysActivity',\n",
       " 'Fruits',\n",
       " 'Veggies',\n",
       " 'AnyHealthcare',\n",
       " 'NoDocbcCost',\n",
       " 'DiffWalk',\n",
       " 'Sex',\n",
       " 'BMI',\n",
       " 'GenHlth',\n",
       " 'MentHlth',\n",
       " 'PhysHlth']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_18 = ChiSqSelector(featuresCol=\"features\", outputCol=\"selected_features\", \\\n",
    "                         labelCol=\"Diabetes\", numTopFeatures=18)\n",
    "model_18 = selector_18.fit(balanced_data)\n",
    "df_18 = model_18.transform(balanced_data)\n",
    "selected_indices_18 = model_18.selectedFeatures\n",
    "selected_feature_names_18 = [df_18.columns[index] for index in selected_indices_18]\n",
    "selected_feature_names_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b69ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Diabetes: double (nullable = true)\n",
      " |-- HighBP: double (nullable = true)\n",
      " |-- HighChol: double (nullable = true)\n",
      " |-- CholCheck: double (nullable = true)\n",
      " |-- Smoker: double (nullable = true)\n",
      " |-- Stroke: double (nullable = true)\n",
      " |-- HeartDiseaseorAttack: double (nullable = true)\n",
      " |-- PhysActivity: double (nullable = true)\n",
      " |-- Fruits: double (nullable = true)\n",
      " |-- Veggies: double (nullable = true)\n",
      " |-- HvyAlcoholConsump: double (nullable = true)\n",
      " |-- AnyHealthcare: double (nullable = true)\n",
      " |-- NoDocbcCost: double (nullable = true)\n",
      " |-- DiffWalk: double (nullable = true)\n",
      " |-- Sex: double (nullable = true)\n",
      " |-- BMI: double (nullable = true)\n",
      " |-- GenHlth: double (nullable = true)\n",
      " |-- MentHlth: double (nullable = true)\n",
      " |-- PhysHlth: double (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Education: double (nullable = true)\n",
      " |-- Income: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- selected_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_18.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a324bbe6",
   "metadata": {},
   "source": [
    "Train test data set split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afda1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_13,test_data_13 = df_13.select(['Diabetes', 'features']).randomSplit([0.8,0.2])\n",
    "train_data_18,test_data_18 = df_18.select(['Diabetes', 'features']).randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ffdaab",
   "metadata": {},
   "source": [
    "Fit Random Forest models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4480ecc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 22:21:47 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rfc_13 = RandomForestClassifier(labelCol='Diabetes',featuresCol='features',numTrees=5)\n",
    "rfc_model_13 = rfc_13.fit(train_data_13)\n",
    "rfc_predictions_13 = rfc_model_13.transform(test_data_13)\n",
    "\n",
    "rfc_18 = RandomForestClassifier(labelCol='Diabetes',featuresCol='features',numTrees=5)\n",
    "rfc_model_18 = rfc_18.fit(train_data_18)\n",
    "rfc_predictions_18 = rfc_model_18.transform(test_data_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a36c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8770bc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances with 13 features selected:\n",
      "Diabetes: 0.2946739432390753\n",
      "HighBP: 0.18010727160221165\n",
      "HighChol: 0.001884897754532452\n",
      "CholCheck: 0.0\n",
      "Smoker: 0.0\n",
      "Stroke: 0.07125229299318833\n",
      "HeartDiseaseorAttack: 0.00040143573109477387\n",
      "PhysActivity: 0.0\n",
      "Fruits: 0.0\n",
      "Veggies: 0.0037464973386321008\n",
      "AnyHealthcare: 0.0\n",
      "NoDocbcCost: 0.0\n",
      "DiffWalk: 0.08955484588924426\n",
      "\n",
      "Random Forest Feature Importances with 18 features selected:\n",
      "Diabetes: 0.19038681054852624\n",
      "HighBP: 0.18324729287987845\n",
      "HighChol: 0.0016371884569633514\n",
      "CholCheck: 0.0\n",
      "Smoker: 0.0012985031082045101\n",
      "Stroke: 0.0774202830560662\n",
      "HeartDiseaseorAttack: 0.0016105034010983695\n",
      "PhysActivity: 0.00012035488822141431\n",
      "Fruits: 0.0\n",
      "Veggies: 0.006218193637338278\n",
      "AnyHealthcare: 0.0\n",
      "NoDocbcCost: 0.0\n",
      "DiffWalk: 0.07963826962368326\n",
      "Sex: 0.0\n",
      "BMI: 0.05009016013139143\n",
      "GenHlth: 0.37843599492649216\n",
      "MentHlth: 0.00018196688478028434\n",
      "PhysHlth: 0.0018211825845470414\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Feature Importances\n",
    "rfc_importances_13 = rfc_model_13.featureImportances\n",
    "print(\"Random Forest Feature Importances with 13 features selected:\")\n",
    "for i, (col, importance) in enumerate(zip(selected_feature_names_13, rfc_importances_13)):\n",
    "    print(f\"{col}: {importance}\")\n",
    "    \n",
    "rfc_importances_18 = rfc_model_18.featureImportances\n",
    "print(\"\\nRandom Forest Feature Importances with 18 features selected:\")\n",
    "for i, (col, importance) in enumerate(zip(selected_feature_names_18, rfc_importances_18)):\n",
    "    print(f\"{col}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "766115c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve for 13 features: 0.8042322455957966\n",
      "Accuracy for 13 features: 0.8042322455957965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve for 18 features: 0.8057071074055722\n",
      "Accuracy for 18 features: 0.8057071074055722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_eval = BinaryClassificationEvaluator(labelCol = 'Diabetes')\n",
    "\n",
    "rfc_auc_13 = result_eval.evaluate(rfc_predictions_13, {result_eval.metricName: \"areaUnderROC\"})\n",
    "rfc_acc_13 = result_eval.evaluate(rfc_predictions_13)\n",
    "print(\"Area Under Curve for 13 features:\",rfc_auc_13)\n",
    "print(\"Accuracy for 13 features:\",rfc_acc_13)\n",
    "\n",
    "rfc_auc_18 = result_eval.evaluate(rfc_predictions_18, {result_eval.metricName: \"areaUnderROC\"})\n",
    "rfc_acc_18 = result_eval.evaluate(rfc_predictions_18)\n",
    "print(\"Area Under Curve for 18 features:\",rfc_auc_18)\n",
    "print(\"Accuracy for 18 features:\",rfc_acc_18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e83322d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve for 5 trees: 0.8057071074055723\n",
      "Accuracy for 5 trees: 0.805707107405572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve for 10 trees: 0.8084779431638714\n",
      "Accuracy for 10 trees: 0.8084780250192647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve for 20 trees: 0.809138352476854\n",
      "Accuracy for 20 trees: 0.8091343927222041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve for 50 trees: 0.8125208015018174\n",
      "Accuracy for 50 trees: 0.8125212414745564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve for 100 trees: 0.8129806344054917\n",
      "Accuracy for 100 trees: 0.8129760505034677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve for 150 trees: 0.8134656378425997\n",
      "Accuracy for 150 trees: 0.8134620566691437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 22:36:42 WARN DAGScheduler: Broadcasting large task binary with size 1035.0 KiB\n",
      "24/05/23 22:36:45 WARN DAGScheduler: Broadcasting large task binary with size 1035.0 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve for 200 trees: 0.8137769952947884\n",
      "Accuracy for 200 trees: 0.8137680423611482\n"
     ]
    }
   ],
   "source": [
    "# iterate through numTrees = [5, 10, 20, 50, 100, 150, 200]\n",
    "num_Trees = [5, 10, 20, 50, 100, 150, 200]\n",
    "result_eval = BinaryClassificationEvaluator(labelCol = 'Diabetes')\n",
    "for numtree in num_Trees:\n",
    "    rfc = RandomForestClassifier(labelCol='Diabetes',featuresCol='features',numTrees=numtree)\n",
    "    rfc_model = rfc.fit(train_data_18)\n",
    "    rfc_predictions = rfc_model.transform(test_data_18)\n",
    "    rfc_auc = result_eval.evaluate(rfc_predictions, {result_eval.metricName: \"areaUnderROC\"})\n",
    "    rfc_acc = result_eval.evaluate(rfc_predictions)\n",
    "    print(\"Area Under Curve for\",  numtree, \"trees:\",rfc_auc)\n",
    "    print(\"Accuracy for\",  numtree, \"trees:\",rfc_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
