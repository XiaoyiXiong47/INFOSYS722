{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22615bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/INFOSYS722/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/23 09:26:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "# findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "findspark.init('../spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('modelling').getOrCreate()\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier, DecisionTreeClassifier,MultilayerPerceptronClassifier)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e708762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Diabetes: double (nullable = true)\n",
      " |-- HighBP: double (nullable = true)\n",
      " |-- HighChol: double (nullable = true)\n",
      " |-- CholCheck: double (nullable = true)\n",
      " |-- Smoker: double (nullable = true)\n",
      " |-- Stroke: double (nullable = true)\n",
      " |-- HeartDiseaseorAttack: double (nullable = true)\n",
      " |-- PhysActivity: double (nullable = true)\n",
      " |-- Fruits: double (nullable = true)\n",
      " |-- Veggies: double (nullable = true)\n",
      " |-- AnyHealthcare: double (nullable = true)\n",
      " |-- NoDocbcCost: double (nullable = true)\n",
      " |-- DiffWalk: double (nullable = true)\n",
      " |-- Sex: double (nullable = true)\n",
      " |-- BMI: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"data.csv\", header=True)\n",
    "for c in df.columns:\n",
    "    df = df.withColumn(c,col(c).cast('double'))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b8ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "features_names = ['HighBP', 'HighChol', 'CholCheck', 'Smoker','Stroke', 'HeartDiseaseorAttack', \\\n",
    "                  'PhysActivity', 'Fruits','Veggies', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', \\\n",
    "                 'Sex', 'BMI']\n",
    "assembler = VectorAssembler(inputCols=features_names, outputCol=\"features\")\n",
    "\n",
    "# assembler = VectorAssembler(inputCols=df.columns, outputCol=\"features\")\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936e75d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Diabetes: double (nullable = true)\n",
      " |-- HighBP: double (nullable = true)\n",
      " |-- HighChol: double (nullable = true)\n",
      " |-- CholCheck: double (nullable = true)\n",
      " |-- Smoker: double (nullable = true)\n",
      " |-- Stroke: double (nullable = true)\n",
      " |-- HeartDiseaseorAttack: double (nullable = true)\n",
      " |-- PhysActivity: double (nullable = true)\n",
      " |-- Fruits: double (nullable = true)\n",
      " |-- Veggies: double (nullable = true)\n",
      " |-- AnyHealthcare: double (nullable = true)\n",
      " |-- NoDocbcCost: double (nullable = true)\n",
      " |-- DiffWalk: double (nullable = true)\n",
      " |-- Sex: double (nullable = true)\n",
      " |-- BMI: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d714cd",
   "metadata": {},
   "source": [
    "# Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b2e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = df.select(['Diabetes', 'features']).randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a7e14af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49136\n",
      "21146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 180:============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(train_data.count())\n",
    "print(test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a37d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|Diabetes|            features|\n",
      "+--------+--------------------+\n",
      "|     0.0|(14,[0,1,2,3,4,5,...|\n",
      "|     0.0|(14,[0,1,2,3,4,6,...|\n",
      "|     0.0|(14,[0,1,2,3,4,6,...|\n",
      "|     0.0|(14,[0,1,2,3,4,7,...|\n",
      "|     0.0|(14,[0,1,2,3,4,8,...|\n",
      "|     0.0|(14,[0,1,2,3,4,8,...|\n",
      "|     0.0|(14,[0,1,2,3,4,8,...|\n",
      "|     0.0|(14,[0,1,2,3,4,8,...|\n",
      "|     0.0|(14,[0,1,2,3,4,9,...|\n",
      "|     0.0|(14,[0,1,2,3,4,9,...|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 183:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53c871fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 1.03344617076064\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "major_df = df.filter(col(\"Diabetes\") == 0)\n",
    "minor_df = df.filter(col(\"Diabetes\") == 1)\n",
    "ratio = major_df.count()/minor_df.count()\n",
    "print(\"ratio: {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff6f7d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Diabetes: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c1a41",
   "metadata": {},
   "source": [
    "# Fit machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b77df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store the results for benchmark ML methods\n",
    "bench_mark_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38da2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol='Diabetes',featuresCol='features')\n",
    "# svm = SVMWithSGD.train(train_data, iterations=100)\n",
    "\n",
    "# mlpc = MultilayerPerceptronClassifier(featuresCol='features',labelCol='Diabetes',layers = [15,16,2],\\\n",
    "#  maxIter=1000,blockSize=8,seed=7,solver='gd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de2825",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='Diabetes',featuresCol='features')\n",
    "rfc = RandomForestClassifier(labelCol='Diabetes',featuresCol='features',numTrees=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1cf4782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 10:22:47 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/05/23 10:22:47 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "lr_model = lr.fit(train_data)\n",
    "# mlpc_model = mlpc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e589ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_predictions = dtc_model.transform(test_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)\n",
    "lr_predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60c0ab4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random ForestFeature Importances:\n",
      "HighBP: 0.4462557969356233\n",
      "HighChol: 0.16421160668499454\n",
      "CholCheck: 0.014723395373918733\n",
      "Smoker: 0.0005494524775009405\n",
      "Stroke: 0.005675011630538262\n",
      "HeartDiseaseorAttack: 0.043483735671290366\n",
      "PhysActivity: 0.004150135220140656\n",
      "Fruits: 0.00035694790983382686\n",
      "Veggies: 0.0014963733797508558\n",
      "HvyAlcoholConsump: 0.00017354195653402797\n",
      "AnyHealthcare: 0.00045653933795790727\n",
      "NoDocbcCost: 0.10632524680589651\n",
      "DiffWalk: 0.00031378785990760427\n",
      "Sex: 0.2118284287561125\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Feature Importances\n",
    "cols = ['HighBP', 'HighChol', 'CholCheck',\n",
    "       'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits',\n",
    "       'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost',\n",
    "       'DiffWalk', 'Sex', 'BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age',\n",
    "       'Education', 'Income']\n",
    "rfc_importances = rfc_model.featureImportances\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "for i, (col, importance) in enumerate(zip(cols, rfc_importances)):\n",
    "    print(f\"{col}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65687d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Feature Importances:\n",
      "HighBP: 0.6139061989981442\n",
      "HighChol: 0.08545221407977839\n",
      "CholCheck: 0.0009266833671068595\n",
      "Smoker: 0.0\n",
      "Stroke: 0.0\n",
      "HeartDiseaseorAttack: 0.033658100049640906\n",
      "PhysActivity: 0.0\n",
      "Fruits: 0.0\n",
      "Veggies: 0.0\n",
      "HvyAlcoholConsump: 0.0\n",
      "AnyHealthcare: 0.0\n",
      "NoDocbcCost: 0.1077347225920033\n",
      "DiffWalk: 0.0\n",
      "Sex: 0.15832208091332642\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classification Feature Importances\n",
    "dtc_importances = dtc_model.featureImportances\n",
    "print(\"Decision Tree Classification Feature Importances:\")\n",
    "for i, (col, importance) in enumerate(zip(cols, dtc_importances)):\n",
    "    print(f\"{col}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e993331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "HighBP: 0.4462557969356233\n",
      "HighChol: 0.16421160668499454\n",
      "CholCheck: 0.014723395373918733\n",
      "Smoker: 0.0005494524775009405\n",
      "Stroke: 0.005675011630538262\n",
      "HeartDiseaseorAttack: 0.043483735671290366\n",
      "PhysActivity: 0.004150135220140656\n",
      "Fruits: 0.00035694790983382686\n",
      "Veggies: 0.0014963733797508558\n",
      "HvyAlcoholConsump: 0.00017354195653402797\n",
      "AnyHealthcare: 0.00045653933795790727\n",
      "NoDocbcCost: 0.10632524680589651\n",
      "DiffWalk: 0.00031378785990760427\n",
      "Sex: 0.2118284287561125\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfe5c8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "|Diabetes|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "|     0.0|(14,[0,1,2,3,4,6,...|[-1.0322071113641...|[0.26265643339459...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,8,...|[-0.7402275728270...|[0.3229543818546,...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,9,...|[-1.1803305099809...|[0.23499277486601...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,9,...|[-1.3879229558628...|[0.19973955214789...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,9,...|[-1.6647128837053...|[0.15913036238002...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|[-1.6622143527014...|[0.15946497034473...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|[-0.5195982607236...|[0.37294617856346...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|[-0.7271907066055...|[0.32581150999934...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|[-1.0039806344479...|[0.26815950134669...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|[-1.3499680442510...|[0.20587559622392...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|[-1.7651529360147...|[0.14614614486938...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,9,...|[-2.2052558731687...|[0.09927950186132...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,9,...|[-2.3436508370900...|[0.08757176260795...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,9,...|[-1.2462528451614...|[0.22334946320925...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,9,...|[-1.3846478090826...|[0.20026357846510...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,9,...|[-1.5922402549645...|[0.16906894216682...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,9,...|[-1.6614377369251...|[0.15956909226564...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,9,...|[-2.2150175926101...|[0.09840998702389...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,9,...|[-2.2842150745707...|[0.09243872645718...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,9,...|[-0.7764030258027...|[0.31509563363000...|       1.0|\n",
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 106:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b803058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65ec138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval = BinaryClassificationEvaluator(labelCol = 'Diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2edaf2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 71:>                                                         (0 + 2) / 2]\r",
      "\r",
      "[Stage 71:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier: 0.6733305428950853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Classifier:\", result_eval.evaluate(dtc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fac0f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forecast Classifier: 0.7844778248680947\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forecast Classifier:\",result_eval.evaluate(rfc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b84ffed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier: 0.7853488896476969\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Classifier:\",result_eval.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6334aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/INFOSYS722/iteration4/../spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Diabetes: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n",
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "|Diabetes|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "|     0.0|(14,[0,1,2,3,4,5,...|[-1.4848156009922...|[0.18470115280890...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,6,...|[-0.6372889895136...|[0.34585962385541...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,6,...|[-0.7064864714743...|[0.33037566585096...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,7,...|[-1.1742301666133...|[0.23609121310176...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,8,...|[-0.6018326089057...|[0.35392453374178...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,8,...|[-0.8094250547876...|[0.30801302656831...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,8,...|[-0.9478200187088...|[0.27932344507922...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,8,...|[-1.0170175006694...|[0.26560876223831...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,9,...|[-1.8723053295871...|[0.13327520197106...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,4,10...|[-1.4626480114309...|[0.18806265283776...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|[-0.4406723440674...|[0.39158077478717...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|[-0.9010420511346...|[0.28883640262827...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|[-0.9702395330952...|[0.27483276075799...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|[-1.0394370150559...|[0.26125863684673...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|[-1.0394370150559...|[0.26125863684673...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,6,...|[-1.2470294609377...|[0.22321477690135...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|[-0.9347831524873...|[0.28195532493348...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|[-1.0039806344479...|[0.26815950134669...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,8,...|[-1.9727453818966...|[0.12209431134051...|       1.0|\n",
      "|     0.0|(14,[0,1,2,3,5,9,...|[-1.1930879872802...|[0.23270710667867...|       1.0|\n",
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_summay = lr_model.summary\n",
    "lr_summay.predictions.printSchema()\n",
    "lr_summay.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cdf1cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"Diabetes\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75cdc5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc = acc_evaluator.evaluate(rfc_predictions)\n",
    "lr_acc = acc_evaluator.evaluate(lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e404238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0dbdb0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "A single decision tree has an accuracy of: 70.91%\n",
      "----------------------------------------\n",
      "A random forest ensemble has an accuracy of: 71.28%\n",
      "----------------------------------------\n",
      "A logistic regression model has an accuracy of: 71.50%\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*40)\n",
    "print('A single decision tree has an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*40)\n",
    "print('A random forest ensemble has an accuracy of: {0:2.2f}%'.format(rfc_acc*100))\n",
    "print('-'*40)\n",
    "print('A logistic regression model has an accuracy of: {0:2.2f}%'.format(lr_acc*100))\n",
    "print('-'*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
